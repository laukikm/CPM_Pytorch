{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5m8t0lIg-KO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df9e941-fc04-4e11-f7dc-1a7f9dd5ba4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01LOjGdsunCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760e605f-8eba-44fb-c159-0daa306ad6c1"
      },
      "source": [
        "cd /content/drive/My\\ Drive/CPM_Pytorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CPM_Pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNCi-PjNg-KS"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('TKAgg')\n",
        "\n",
        "from data_loader.dataLoader import CarDataset as Mydata\n",
        "from model.cpm import CPM\n",
        "from src.util import heatmap_image,save_images,PCK\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import configparser\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageDraw\n",
        "from src.compute_origin import HumanSortKey,GetIntrinsicMatrix,DrawOrigin"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-2JEKS5jfAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee59fda-6959-406f-a03d-e104993840d2"
      },
      "source": [
        "#Hyperparams\n",
        "config = configparser.ConfigParser()\n",
        "config.read('conf_online.text')\n",
        "\n",
        "train_data_dir = config.get('data', 'train_data_dir')\n",
        "\n",
        "annotation_save_dir=config.get('data', 'annotation_save_dir')\n",
        "keypoints_dir=config.get('data','keypoints_file_dir')\n",
        "\n",
        "save_dir = config.get('data', 'save_dir')\n",
        "\n",
        "learning_rate = config.getfloat('training', 'learning_rate')\n",
        "batch_size = config.getint('training', 'batch_size')\n",
        "epochs = config.getint('training', 'epochs')\n",
        "begin_epoch = config.getint('training', 'begin_epoch')\n",
        "n_keypoints=config.getint('training', 'n_keypoints')  \n",
        "model_save_dir=config.get('data', 'model_save_dir')+\"_\"+str(n_keypoints)+\"/\"\n",
        "print(begin_epoch)\n",
        "print(model_save_dir)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "models_high_density_4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx6XxRP-nL4Y"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        " \n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REXWM9sZsjyQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad9d56a-4456-40a0-a589-08e2d88ec8bc"
      },
      "source": [
        "# *********************** Build dataset ***********************\n",
        "train_data = Mydata(data_dir=train_data_dir,n_keypoints=n_keypoints)\n",
        "\n",
        "\n",
        "print ('Train dataset total number of images sequence is ----' + str(len(train_data)))\n",
        "\n",
        "# Data Loader\n",
        "train_dataset = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train dataset total number of images sequence is ----528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_w2352-l6tA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e8405db-8c0e-47f4-d11f-78dad7ae7751"
      },
      "source": [
        "train_data.images_dir.sort(key=HumanSortKey)\n",
        "train_data.label_dir.sort(key=HumanSortKey)\n",
        "train_data.label_dir[0:10]\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive//My Drive/Final Data/mustang/Labels/labels1.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels2.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels3.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels4.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels5.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels6.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels7.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels8.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels9.txt',\n",
              " '/content/drive//My Drive/Final Data/mustang/Labels/labels10.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF4BqAR9slCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c645469a-1af4-4bf1-c84d-c9e4942dd565"
      },
      "source": [
        "net = CPM(out_c=n_keypoints)#,pooling_padding=1,pooling_stride=1,lower_pool_stride=1,lower_pool_padding=4)\n",
        "\n",
        "device_ids = [0]  \n",
        "if cuda:\n",
        "    net = net.cuda(device_ids[0])\n",
        "    net = nn.DataParallel(net, device_ids=device_ids)\n",
        "print(model_save_dir)\n",
        "if begin_epoch > 0:\n",
        "    save_path =model_save_dir+'model_epoch' + str(begin_epoch) + '.pth'\n",
        "    state_dict = torch.load(save_path)\n",
        "    net.load_state_dict(state_dict)\n",
        "    print(\"Loaded model trained for \",begin_epoch,\" epochs\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "models_high_density_4/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h8Bs0aIss_2"
      },
      "source": [
        "def train():\n",
        "    # *********************** initialize optimizer ***********************\n",
        "    optimizer = optim.Adam(params=net.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
        "    criterion = nn.MSELoss(size_average=True)                       # loss function MSE average\n",
        "\n",
        "    net.train()\n",
        "    for epoch in range(begin_epoch, epochs + 1):\n",
        "        print ('epoch....................' + str(epoch))\n",
        "        \n",
        "        for step, (image, label_map, center_map, imgs) in enumerate(train_dataset):\n",
        "            \n",
        "            image = Variable(image.cuda() if cuda else image)                   # 4D Tensor\n",
        "            # Batch_size  *  3  *  width(368)  *  height(368)\n",
        "\n",
        "            # 4D Tensor to 5D Tensor\n",
        "            label_map = torch.stack([label_map]*6, dim=1)\n",
        "            # Batch_size  *  21 *   45  *  45\n",
        "            # Batch_size  *   6 *   21  *  45  *  45\n",
        "            label_map = Variable(label_map.cuda() if cuda else label_map)\n",
        "\n",
        "            center_map = Variable(center_map.cuda() if cuda else center_map)    # 4D Tensor\n",
        "            # Batch_size  *  width(368) * height(368)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred_6 = net(image, center_map)  # 5D tensor:  batch size * stages * 21 * 45 * 45 #This is huge\n",
        "\n",
        "            # ******************** calculate loss of each joints ********************\n",
        "            loss = criterion(pred_6, label_map)\n",
        "\n",
        "            # backward\n",
        "            loss.backward()\n",
        "            loss=loss.detach()\n",
        "            #import ipdb\n",
        "            #ipdb.set_trace()\n",
        "            \n",
        "            optimizer.step() #Not using SGD\n",
        "            #gc.collect()\n",
        "\n",
        "            if step % 10 == 0:\n",
        "                print ('--step .....' + str(step))\n",
        "                print ('--loss ',loss.item()*10000)\n",
        "                gb_factor=10**9\n",
        "                print('--gpu memory=',torch.cuda.memory_allocated()/gb_factor)\n",
        "\n",
        "            #if step % 40 == 0:\n",
        "              #torch.save(net.state_dict(), os.path.join(save_dir, 'model_epoch{:d}.pth'.format(epoch)))\n",
        "            #    save_images(label_map[:, 5, :, :, :], pred_6[:, 5, :, :, :], step, epoch, imgs)\n",
        "\n",
        "        if epoch % 10 == 0 and epoch>0:\n",
        "            torch.save(net.state_dict(), os.path.join(model_save_dir, 'model_epoch{:d}.pth'.format(epoch)))\n",
        "        \n",
        "            #Delete tensors from memory\n",
        "            #del image,label_map,center_map,pred_6\n",
        "\n",
        "    print ('train done!')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC9yZJGAuRak",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "d6ad5ef0-982e-4eb8-8525-051c8171ccb0"
      },
      "source": [
        "train()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch....................0\n",
            "--step .....0\n",
            "--loss  1563.8580918312073\n",
            "--gpu memory= 0.532942336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-201e81353f71>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'epoch....................'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m                   \u001b[0;31m# 4D Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/CPM_Pytorch/data_loader/dataLoader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# get image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# read image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m      \u001b[0;31m# weight 256    * height 256 * 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mratio_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mratio_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQ12jUuuS9m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12618851-f022-443c-c662-13bc5e1c6714"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov 20 16:32:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7xOnICuvD_v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb2oj3289Uml"
      },
      "source": [
        "def get_locations(pred_6):\n",
        "  locations=[]\n",
        "  label_locations=[]\n",
        "  for keypoint_map in pred_6:\n",
        "    \n",
        "    flat_tensor=keypoint_map.view(1,-1)\n",
        "    val=torch.argmax(flat_tensor).cpu().numpy()\n",
        "    locations.append(np.array([(val%45)*(368/45),val//45*(368/45)]) ) #return values corresponding to a 368x368 image. These are in the OpenCV axes coordinates\n",
        "  return np.array(locations)  #x y locations of the heatmap\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cox6NaBS_VoO"
      },
      "source": [
        "def generate_output_image(h,w,locations,colors=['red','blue','green','yellow']):\n",
        "  \n",
        "  empty_tensor=torch.zeros((3,w,h))\n",
        "  output_image=transforms.ToPILImage()(empty_tensor)\n",
        "  draw = ImageDraw.Draw(output_image)\n",
        "\n",
        "  i=0\n",
        "  for x,y in locations:\n",
        "    draw.ellipse((x, y, x+5, y+5), fill = colors[i], outline =colors[i])\n",
        "    i+=1\n",
        "  output_image.putalpha(150)\n",
        "  return output_image\n",
        "\n",
        "#output_image=generate_output_image(output.clone(),locations)\n",
        "#output_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGqnmdB-Ae8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671973d3-56ff-483e-cf92-59072402862c"
      },
      "source": [
        "#Read the 3d keypoints\n",
        "keypoints_3d=pd.read_csv(keypoints_dir)\n",
        "\n",
        "usable_object_points=keypoints_3d.to_numpy()[0:n_keypoints] #Only use the first n_keypoints keypoints\n",
        "\n",
        "def GetFOV(train_data_dir,i):\n",
        "  #returns fov in degrees\n",
        "  fov_dir=sorted(glob.glob(train_data_dir+\"FOV_Labels/*.txt\"),key=HumanSortKey)\n",
        "  fov_file=pd.read_csv(fov_dir[i]) #This value is in degrees\n",
        "  fov=fov_file['FOV'][0] #FOV in degrees\n",
        "  return fov\n",
        "\n",
        "def calculate_angle(rvec_pred,rvec_gt):\n",
        "  #Returns the angle between the frames IN DEGREES\n",
        "  R_pred,J_pred=cv2.Rodrigues(rvec_pred)\n",
        "  R_gt,J_gt=cv2.Rodrigues(rvec_gt)\n",
        "\n",
        "  dR=np.matmul(R_pred,np.transpose(R_gt))\n",
        "  theta=np.arccos((np.trace(dR)-1)/2)\n",
        "  return theta*180/np.pi #Convert from radians to degrees\n",
        "\n",
        "def calculate_distance(tvec_pred,tvec_gt):\n",
        "  #returns the distance between the objects IN CENTIMETERS\n",
        "  dt=tvec_pred-tvec_gt\n",
        "  return np.sum(np.sqrt(dt*dt))\n",
        "\n",
        "#Function to save a prediction from an image\n",
        "def predict_output(net,train_data,i):\n",
        "  image,labels,center_map,img_str=train_data[i]\n",
        "  pred_6=net(torch.unsqueeze(image,dim=0),torch.unsqueeze(center_map,dim=0))[0][-1] #Final stage output\n",
        "  locations=get_locations(pred_6.detach()) #Get locations from the heatmap\n",
        "  \n",
        "  original_size_image=Image.open(train_data.images_dir[i])\n",
        "  locations_original_size=900/368*locations #Convert from 368x368 to 900x900, since the image labels are in the same order too\n",
        "  fov=GetFOV(train_data_dir,i)\n",
        "\n",
        "  camera_matrix=GetIntrinsicMatrix(900,900,fov) #This is the same regardless of whether we use labels or predictions\n",
        "\n",
        "  ret_val,rvec_pred,tvec_pred=cv2.solvePnP(objectPoints=usable_object_points,imagePoints=locations_original_size,cameraMatrix=camera_matrix\n",
        "                                             ,distCoeffs=np.zeros((4,1)))\n",
        "  \n",
        "  usable_labels=pd.read_csv(train_data.label_dir[i],delimiter=\" \").to_numpy()[0:n_keypoints]\n",
        "  ret_val,rvec_gt,tvec_gt=cv2.solvePnP(objectPoints=usable_object_points,imagePoints=usable_labels,cameraMatrix=camera_matrix\n",
        "                                             ,distCoeffs=np.zeros((4,1)))\n",
        "  \n",
        "  background=original_size_image\n",
        "  output=pred_6.clone().detach()*0\n",
        "\n",
        "  #output_image=generate_output_image(900,900,usable_labels)\n",
        "  #background.paste(output_image,(0,0),output_image)\n",
        "  #background.show()\n",
        "  #print(usable_labels)\n",
        " \n",
        "\n",
        "  dt=calculate_distance(tvec_pred,tvec_gt)\n",
        "  theta=calculate_angle(rvec_pred,rvec_gt)\n",
        "\n",
        "  return(dt,theta)\n",
        "  #return (rvec_gt,tvec_gt,rvec_pred,tvec_pred)\n",
        "\n",
        "distances=[]\n",
        "angles=[]\n",
        "for i in range(0,339):\n",
        "  dt,theta=predict_output(net,train_data,i)\n",
        "  distances.append(dt)\n",
        "  angles.append(theta)\n",
        "\n",
        "print(\"Average Distance=\",np.mean(distances),\"cm\")\n",
        "print(\"Average Angle=\",np.mean(angles),\"degrees\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Distance= 412.55787205112955 cm\n",
            "Average Angle= 27.90966423663084 degrees\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1YlNdC1HXnn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "961a090c-3851-4282-e913-92aee59194f3"
      },
      "source": [
        "#Prediction\n",
        "i=0\n",
        "for image,labels,center_map,img_str in train_data:\n",
        "  pred_6=net(torch.unsqueeze(image,dim=0),torch.unsqueeze(center_map,dim=0))[0][-1] #Final stage output\n",
        "  output=pred_6.clone().detach()*0\n",
        "  pil_image=transforms.ToPILImage()(image)\n",
        "  background=pil_image\n",
        "\n",
        "  output_image=generate_output_image(368,368,get_locations(pred_6))\n",
        "  background.paste(output_image,(0,0),output_image)\n",
        "  background.save(annotation_save_dir+'Image'+str(i)+'.PNG')\n",
        "  i+=1\n",
        "  #import ipdb\n",
        "  #ipdb.set_trace()\n",
        "  print(\"Saving Image \",i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c006f50a7235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mbackground\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0moutput_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_output_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m368\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m368\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mbackground\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_save_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Image'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.PNG'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-6f6f464e3869>\u001b[0m in \u001b[0;36mgenerate_output_image\u001b[0;34m(h, w, locations, colors)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mellipse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutline\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0moutput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputalpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALvBG-1wwvP1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "5ce5b72b-eeb9-4051-be61-ce52198ca2cf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-28935580a9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x55QWgURgbjx"
      },
      "source": [
        "golf_annotation_save_dir='/content/drive/My Drive/Final Data/golf/Annotated_Images/'\n",
        "golf_train_data_dir='/content/drive/My Drive/Final Data/golf/'\n",
        "\n",
        "golf_train_data = Mydata(data_dir=golf_train_data_dir,n_keypoints=4)\n",
        "\n",
        "golf_train_data.images_dir.sort(key=HumanSortKey)\n",
        "golf_train_data.label_dir.sort(key=HumanSortKey)\n",
        "\n",
        "#Predict on Golf using network trained on Mustang\n",
        "i=0\n",
        "for image,labels,center_map,img_str in golf_train_data:\n",
        "  pred_6=net(torch.unsqueeze(image,dim=0),torch.unsqueeze(center_map,dim=0))[0][-1] #Final stage output\n",
        "  output=pred_6.clone().detach()*0\n",
        "  pil_image=transforms.ToPILImage()(image)\n",
        "  background=pil_image\n",
        "\n",
        "  output_image=generate_output_image(output,get_locations(pred_6))\n",
        "  background.paste(output_image,(0,0),output_image)\n",
        "  background.save(golf_annotation_save_dir+'Image'+str(i)+'.PNG')\n",
        "  i+=1\n",
        "  #import ipdb\n",
        "  #ipdb.set_trace()\n",
        "  print(\"Saving Image \",i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHNs40BzgrHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5febe191-9cd2-4fe0-e7bf-4b801f285a14"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Final Data/golf/Labels/labels1.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels7.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels3.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels2.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels4.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels5.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels6.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels8.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels13.txt',\n",
              " '/content/drive/My Drive/Final Data/golf/Labels/labels12.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xn8jYrAqk3_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}